{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession #Importing the Libraries\n",
    "# Creating Spark Session\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "# Reading /loading the Dataset from CSV file\n",
    "cardf = spark.read.load(\"C:\\\\Users\\\\SGKsk\\\\Downloads\\\\cars.csv\", format=\"csv\", header = True,inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Car: string (nullable = true)\n",
      " |-- MPG: double (nullable = true)\n",
      " |-- Cylinders: integer (nullable = true)\n",
      " |-- Displacement: double (nullable = true)\n",
      " |-- Horsepower: integer (nullable = true)\n",
      " |-- Weight: integer (nullable = true)\n",
      " |-- Acceleration: double (nullable = true)\n",
      " |-- Model: integer (nullable = true)\n",
      " |-- Origin: string (nullable = true)\n",
      " |-- quantity: integer (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#see the types of columns in DataFrame\n",
    "cardf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Car',\n",
       " 'MPG',\n",
       " 'Cylinders',\n",
       " 'Displacement',\n",
       " 'Horsepower',\n",
       " 'Weight',\n",
       " 'Acceleration',\n",
       " 'Model',\n",
       " 'Origin',\n",
       " 'quantity',\n",
       " 'city']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#column names\n",
    "cardf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+---------+------------+----------+------+------------+-----+------+--------+-------+\n",
      "|                 Car| MPG|Cylinders|Displacement|Horsepower|Weight|Acceleration|Model|Origin|quantity|   city|\n",
      "+--------------------+----+---------+------------+----------+------+------------+-----+------+--------+-------+\n",
      "|AMC Ambassador Br...|13.0|        8|       360.0|       175|  3821|        11.0|   73|    US|      25|NewYork|\n",
      "|  AMC Ambassador DPL|15.0|        8|       390.0|       190|  3850|         8.5|   70|    US|       2|     NJ|\n",
      "|  AMC Ambassador SST|17.0|        8|       304.0|       150|  3672|        11.5|   72|    US|       4| DALLAS|\n",
      "|         AMC Concord|19.4|        6|       232.0|        90|  3210|        17.2|   78|    US|      52|  TEXAS|\n",
      "|         AMC Concord|24.3|        4|       151.0|        90|  3003|        20.1|   80|    US|      42|     OH|\n",
      "|     AMC Concord d/l|18.1|        6|       258.0|       120|  3410|        15.1|   78|    US|       4|NewYork|\n",
      "|      AMC Concord DL|23.0|        4|       151.0|         0|  3035|        20.5|   82|    US|      45|     NJ|\n",
      "|    AMC Concord DL 6|20.2|        6|       232.0|        90|  3265|        18.2|   79|    US|     328| DALLAS|\n",
      "|         AMC Gremlin|21.0|        6|       199.0|        90|  2648|        15.0|   70|    US|      68|  TEXAS|\n",
      "|         AMC Gremlin|19.0|        6|       232.0|       100|  2634|        13.0|   71|    US|      78|     OH|\n",
      "|         AMC Gremlin|18.0|        6|       232.0|       100|  2789|        15.0|   73|    US|     152|NewYork|\n",
      "|         AMC Gremlin|20.0|        6|       232.0|       100|  2914|        16.0|   75|    US|     214|     NJ|\n",
      "|          AMC Hornet|18.0|        6|       199.0|        97|  2774|        15.5|   70|    US|      60| DALLAS|\n",
      "|          AMC Hornet|18.0|        6|       232.0|       100|  2945|        16.0|   73|    US|     144|  TEXAS|\n",
      "|          AMC Hornet|19.0|        6|       232.0|       100|  2901|        16.0|   74|    US|     172|     OH|\n",
      "|          AMC Hornet|22.5|        6|       232.0|        90|  3085|        17.6|   76|    US|      28|NewYork|\n",
      "|AMC Hornet Sporta...|18.0|        6|       258.0|       110|  2962|        13.5|   71|    US|      90|     NJ|\n",
      "|         AMC Matador|18.0|        6|       232.0|       100|  3288|        15.5|   71|    US|      82| DALLAS|\n",
      "|         AMC Matador|14.0|        8|       304.0|       150|  3672|        11.5|   73|    US|     131|  TEXAS|\n",
      "|         AMC Matador|16.0|        6|       258.0|       110|  3632|        18.0|   74|    US|     179|NewYork|\n",
      "+--------------------+----+---------+------------+----------+------+------------+-----+------+--------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#dataset\n",
    "cardf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Car='AMC Ambassador Brougham', MPG=13.0, Cylinders=8, Displacement=360.0, Horsepower=175, Weight=3821, Acceleration=11.0, Model=73, Origin='US', quantity=25, city='NewYork')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#head\n",
    "cardf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Car='Volvo 264gl', MPG=17.0, Cylinders=6, Displacement=163.0, Horsepower=125, Weight=3140, Acceleration=13.6, Model=78, Origin='Europe', quantity=320, city='NewYork'),\n",
       " Row(Car='Volvo Diesel', MPG=30.7, Cylinders=6, Displacement=145.0, Horsepower=76, Weight=3160, Acceleration=19.6, Model=81, Origin='Europe', quantity=406, city='NJ')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#last 2 rows\n",
    "cardf.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cardf.columns)  # show number of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Car',\n",
       " 'MPG',\n",
       " 'Cylinders',\n",
       " 'Displacement',\n",
       " 'Horsepower',\n",
       " 'Weight',\n",
       " 'Acceleration',\n",
       " 'Model',\n",
       " 'Origin',\n",
       " 'quantity',\n",
       " 'city']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cardf.columns     # show name of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|summary|                 Car|\n",
      "+-------+--------------------+\n",
      "|  count|                 406|\n",
      "|   mean|                NULL|\n",
      "| stddev|                NULL|\n",
      "|    min|AMC Ambassador Br...|\n",
      "|    max|        Volvo Diesel|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cardf.describe('Car').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+---------+------------+----------+------+------------+-----+------+--------+-------+\n",
      "|                 Car| MPG|Cylinders|Displacement|Horsepower|Weight|Acceleration|Model|Origin|quantity|   city|\n",
      "+--------------------+----+---------+------------+----------+------+------------+-----+------+--------+-------+\n",
      "|         Peugeot 504|27.2|        4|       141.0|        71|  3190|        24.8|   79|Europe|     344|NewYork|\n",
      "|   Volkswagen Pickup|44.0|        4|        97.0|        52|  2130|        24.6|   82|Europe|      96|NewYork|\n",
      "|Volkswagen Dasher...|43.4|        4|        90.0|        48|  2335|        23.7|   80|Europe|     371| DALLAS|\n",
      "|   Volkswagen Type 3|23.0|        4|        97.0|        54|  2254|        23.5|   72|Europe|     104|NewYork|\n",
      "|  Chevrolet Chevette|29.0|        4|        85.0|        52|  2035|        22.2|   76|    US|     240|  TEXAS|\n",
      "|Oldsmobile Cutlas...|23.9|        8|       260.0|        90|  3420|        22.2|   79|    US|     345|NewYork|\n",
      "|     Chevrolet Woody|24.5|        4|        98.0|        60|  2164|        22.1|   76|    US|     241|     OH|\n",
      "|         Peugeot 504|19.0|        4|       120.0|        88|  3270|        21.9|   76|Europe|     254|     OH|\n",
      "|  Mercedes-Benz 240d|30.0|        4|       146.0|        67|  3250|        21.8|   80|Europe|     373| DALLAS|\n",
      "|Volkswagen Rabbit...|44.3|        4|        90.0|        48|  2085|        21.7|   80|Europe|     370|     NJ|\n",
      "+--------------------+----+---------+------------+----------+------+------------+-----+------+--------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cardf.orderBy(cardf.Acceleration.desc()).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 2 Creating the DataFrame from JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Decommisioned: boolean (nullable = true)\n",
      " |-- EstimatedPopulation: long (nullable = true)\n",
      " |-- Lat: double (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- LocationText: string (nullable = true)\n",
      " |-- LocationType: string (nullable = true)\n",
      " |-- Long: double (nullable = true)\n",
      " |-- Notes: string (nullable = true)\n",
      " |-- RecordNumber: long (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- TaxReturnsFiled: long (nullable = true)\n",
      " |-- TotalWages: long (nullable = true)\n",
      " |-- WorldRegion: string (nullable = true)\n",
      " |-- Xaxis: double (nullable = true)\n",
      " |-- Yaxis: double (nullable = true)\n",
      " |-- Zaxis: double (nullable = true)\n",
      " |-- ZipCodeType: string (nullable = true)\n",
      " |-- Zipcode: long (nullable = true)\n",
      "\n",
      "+-------------------+-------+-------------+-------------------+-----+--------------------+--------------------+--------------+-------+-------------+------------+-----+---------------+----------+-----------+-----+-----+-----+-----------+-------+\n",
      "|               City|Country|Decommisioned|EstimatedPopulation|  Lat|            Location|        LocationText|  LocationType|   Long|        Notes|RecordNumber|State|TaxReturnsFiled|TotalWages|WorldRegion|Xaxis|Yaxis|Zaxis|ZipCodeType|Zipcode|\n",
      "+-------------------+-------+-------------+-------------------+-----+--------------------+--------------------+--------------+-------+-------------+------------+-----+---------------+----------+-----------+-----+-----+-----+-----------+-------+\n",
      "|        PARC PARQUE|     US|        false|               NULL|17.96|NA-US-PR-PARC PARQUE|     Parc Parque, PR|NOT ACCEPTABLE| -66.22|         NULL|           1|   PR|           NULL|      NULL|         NA| 0.38|-0.87|  0.3|   STANDARD|    704|\n",
      "|PASEO COSTA DEL SUR|     US|        false|               NULL|17.96|NA-US-PR-PASEO CO...|Paseo Costa Del S...|NOT ACCEPTABLE| -66.22|         NULL|           2|   PR|           NULL|      NULL|         NA| 0.38|-0.87|  0.3|   STANDARD|    704|\n",
      "|       BDA SAN LUIS|     US|        false|               NULL|18.14|NA-US-PR-BDA SAN ...|    Bda San Luis, PR|NOT ACCEPTABLE| -66.26|         NULL|          10|   PR|           NULL|      NULL|         NA| 0.38|-0.86| 0.31|   STANDARD|    709|\n",
      "|  CINGULAR WIRELESS|     US|        false|               NULL|32.72|NA-US-TX-CINGULAR...|Cingular Wireless...|NOT ACCEPTABLE| -97.31|         NULL|       61391|   TX|           NULL|      NULL|         NA| -0.1|-0.83| 0.54|     UNIQUE|  76166|\n",
      "|         FORT WORTH|     US|        false|               4053|32.75| NA-US-TX-FORT WORTH|      Fort Worth, TX|       PRIMARY| -97.33|         NULL|       61392|   TX|           2126| 122396986|         NA| -0.1|-0.83| 0.54|   STANDARD|  76177|\n",
      "|           FT WORTH|     US|        false|               4053|32.75|   NA-US-TX-FT WORTH|        Ft Worth, TX|    ACCEPTABLE| -97.33|         NULL|       61393|   TX|           2126| 122396986|         NA| -0.1|-0.83| 0.54|   STANDARD|  76177|\n",
      "|    URB EUGENE RICE|     US|        false|               NULL|17.96|NA-US-PR-URB EUGE...| Urb Eugene Rice, PR|NOT ACCEPTABLE| -66.22|         NULL|           4|   PR|           NULL|      NULL|         NA| 0.38|-0.87|  0.3|   STANDARD|    704|\n",
      "|               MESA|     US|        false|              26883|33.37|       NA-US-AZ-MESA|            Mesa, AZ|       PRIMARY|-111.64|no NWS data, |       39827|   AZ|          14962| 563792730|         NA| -0.3|-0.77| 0.55|   STANDARD|  85209|\n",
      "|               MESA|     US|        false|              25446|33.38|       NA-US-AZ-MESA|            Mesa, AZ|       PRIMARY|-111.84|         NULL|       39828|   AZ|          14374| 471000465|         NA|-0.31|-0.77| 0.55|   STANDARD|  85210|\n",
      "|           HILLIARD|     US|        false|               7443|30.69|   NA-US-FL-HILLIARD|        Hilliard, FL|       PRIMARY| -81.92|         NULL|       49345|   FL|           3922| 133112149|         NA| 0.12|-0.85| 0.51|   STANDARD|  32046|\n",
      "|             HOLDER|     US|        false|               NULL|28.96|     NA-US-FL-HOLDER|          Holder, FL|       PRIMARY| -82.41|         NULL|       49346|   FL|           NULL|      NULL|         NA| 0.11|-0.86| 0.48|     PO BOX|  34445|\n",
      "|               HOLT|     US|        false|               2190|30.72|       NA-US-FL-HOLT|            Holt, FL|       PRIMARY| -86.67|         NULL|       49347|   FL|           1207|  36395913|         NA| 0.04|-0.85| 0.51|   STANDARD|  32564|\n",
      "|          HOMOSASSA|     US|        false|               NULL|28.78|  NA-US-FL-HOMOSASSA|       Homosassa, FL|       PRIMARY| -82.61|         NULL|       49348|   FL|           NULL|      NULL|         NA| 0.11|-0.86| 0.48|     PO BOX|  34487|\n",
      "|       BDA SAN LUIS|     US|        false|               NULL|18.14|NA-US-PR-BDA SAN ...|    Bda San Luis, PR|NOT ACCEPTABLE| -66.26|         NULL|          10|   PR|           NULL|      NULL|         NA| 0.38|-0.86| 0.31|   STANDARD|    708|\n",
      "|      SECT LANAUSSE|     US|        false|               NULL|17.96|NA-US-PR-SECT LAN...|   Sect Lanausse, PR|NOT ACCEPTABLE| -66.22|         NULL|           3|   PR|           NULL|      NULL|         NA| 0.38|-0.87|  0.3|   STANDARD|    704|\n",
      "|      SPRING GARDEN|     US|        false|               NULL|33.97|NA-US-AL-SPRING G...|   Spring Garden, AL|       PRIMARY| -85.55|         NULL|       54354|   AL|           NULL|      NULL|         NA| 0.06|-0.82| 0.55|     PO BOX|  36275|\n",
      "|        SPRINGVILLE|     US|        false|               7845|33.77|NA-US-AL-SPRINGVILLE|     Springville, AL|       PRIMARY| -86.47|         NULL|       54355|   AL|           4046| 172127599|         NA| 0.05|-0.82| 0.55|   STANDARD|  35146|\n",
      "|        SPRUCE PINE|     US|        false|               1209|34.37|NA-US-AL-SPRUCE PINE|     Spruce Pine, AL|       PRIMARY| -87.69|         NULL|       54356|   AL|            610|  18525517|         NA| 0.03|-0.82| 0.56|   STANDARD|  35585|\n",
      "|           ASH HILL|     US|        false|               1666| 36.4|   NA-US-NC-ASH HILL|        Ash Hill, NC|NOT ACCEPTABLE| -80.56|         NULL|       76511|   NC|            842|  28876493|         NA| 0.13|-0.79| 0.59|   STANDARD|  27007|\n",
      "|           ASHEBORO|     US|        false|              15228|35.71|   NA-US-NC-ASHEBORO|        Asheboro, NC|       PRIMARY| -79.81|         NULL|       76512|   NC|           8355| 215474318|         NA| 0.14|-0.79| 0.58|   STANDARD|  27203|\n",
      "+-------------------+-------+-------------+-------------------+-----+--------------------+--------------------+--------------+-------+-------------+------------+-----+---------------+----------+-----------+-----+-----+-----+-----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#read json file into dataframe\n",
    "df = spark.read.json(\"C:\\\\Users\\\\SGKsk\\\\Downloads\\\\zipcode.json\")\n",
    "df.printSchema()\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------+-----+-----------+-------+\n",
      "|               City|RecordNumber|State|ZipCodeType|Zipcode|\n",
      "+-------------------+------------+-----+-----------+-------+\n",
      "|PASEO COSTA DEL SUR|           2|   PR|   STANDARD|    704|\n",
      "|       BDA SAN LUIS|          10|   PR|   STANDARD|    709|\n",
      "+-------------------+------------+-----+-----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#read multiline json file into dataframe\n",
    "\n",
    "multiline_df = spark.read.option(\"multiline\",\"true\") \\\n",
    "      .json(\"C:\\\\Users\\\\SGKsk\\\\Downloads\\\\multiline-zipcode.json\")\n",
    "multiline_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+-------------+-----+--------------------+--------------------+--------------+------+------------+-----+-----------+-----+-----+-----+-----------+-------+\n",
      "|               City|Country|Decommisioned|  Lat|            Location|        LocationText|  LocationType|  Long|RecordNumber|State|WorldRegion|Xaxis|Yaxis|Zaxis|ZipCodeType|Zipcode|\n",
      "+-------------------+-------+-------------+-----+--------------------+--------------------+--------------+------+------------+-----+-----------+-----+-----+-----+-----------+-------+\n",
      "|PASEO COSTA DEL SUR|     US|        false|17.96|NA-US-PR-PASEO CO...|Paseo Costa Del S...|NOT ACCEPTABLE|-66.22|           2|   PR|         NA| 0.38|-0.87|  0.3|   STANDARD|    704|\n",
      "|       BDA SAN LUIS|     US|        false|18.14|NA-US-PR-BDA SAN ...|    Bda San Luis, PR|NOT ACCEPTABLE|-66.26|          10|   PR|         NA| 0.38|-0.86| 0.31|   STANDARD|    709|\n",
      "|        PARC PARQUE|     US|        false|17.96|NA-US-PR-PARC PARQUE|     Parc Parque, PR|NOT ACCEPTABLE|-66.22|           1|   PR|         NA| 0.38|-0.87|  0.3|   STANDARD|    704|\n",
      "+-------------------+-------+-------------+-----+--------------------+--------------------+--------------+------+------------+-----+-----------+-----+-----+-----+-----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#read multiple JSON files into df\n",
    "df2 = spark.read.json(\n",
    "    [\"C:\\\\Users\\\\SGKsk\\\\Downloads\\\\zipcode2.json\",\"C:\\\\Users\\\\SGKsk\\\\Downloads\\\\zipcode1.json\"])\n",
    "df2.show(4)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read all json files from directory\n",
    "df3 = spark.read.json(\"C:/Users/SGKsk/Downloads/*.json\")\n",
    "df3.show()\n",
    "\n",
    "#stopped bc took too long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- RecordNumber: integer (nullable = true)\n",
      " |-- Zipcode: integer (nullable = true)\n",
      " |-- ZipCodeType: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- LocationType: string (nullable = true)\n",
      " |-- Lat: double (nullable = true)\n",
      " |-- Long: double (nullable = true)\n",
      " |-- Xaxis: integer (nullable = true)\n",
      " |-- Yaxis: double (nullable = true)\n",
      " |-- Zaxis: double (nullable = true)\n",
      " |-- WorldRegion: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- LocationText: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Decommisioned: boolean (nullable = true)\n",
      " |-- TaxReturnsFiled: string (nullable = true)\n",
      " |-- EstimatedPopulation: integer (nullable = true)\n",
      " |-- TotalWages: integer (nullable = true)\n",
      " |-- Notes: string (nullable = true)\n",
      "\n",
      "+------------+-------+-----------+-------------------+-----+--------------+-----+------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-----+\n",
      "|RecordNumber|Zipcode|ZipCodeType|               City|State|  LocationType|  Lat|  Long|Xaxis|Yaxis|Zaxis|WorldRegion|Country|        LocationText|            Location|Decommisioned|TaxReturnsFiled|EstimatedPopulation|TotalWages|Notes|\n",
      "+------------+-------+-----------+-------------------+-----+--------------+-----+------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-----+\n",
      "|           1|    704|   STANDARD|        PARC PARQUE|   PR|NOT ACCEPTABLE|17.96|-66.22| NULL|-0.87|  0.3|         NA|     US|     Parc Parque, PR|NA-US-PR-PARC PARQUE|        false|           NULL|               NULL|      NULL| NULL|\n",
      "|           2|    704|   STANDARD|PASEO COSTA DEL SUR|   PR|NOT ACCEPTABLE|17.96|-66.22| NULL|-0.87|  0.3|         NA|     US|Paseo Costa Del S...|NA-US-PR-PASEO CO...|        false|           NULL|               NULL|      NULL| NULL|\n",
      "|          10|    709|   STANDARD|       BDA SAN LUIS|   PR|NOT ACCEPTABLE|18.14|-66.26| NULL|-0.86| 0.31|         NA|     US|    Bda San Luis, PR|NA-US-PR-BDA SAN ...|        false|           NULL|               NULL|      NULL| NULL|\n",
      "+------------+-------+-----------+-------------------+-----+--------------+-----+------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#define custom schema for zipcode.json bc zipcode.json files have no schema info\n",
    "\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType,BooleanType,DoubleType\n",
    "schema = StructType([\n",
    "      StructField(\"RecordNumber\",IntegerType(),True),\n",
    "      StructField(\"Zipcode\",IntegerType(),True),\n",
    "      StructField(\"ZipCodeType\",StringType(),True),\n",
    "      StructField(\"City\",StringType(),True),\n",
    "      StructField(\"State\",StringType(),True),\n",
    "      StructField(\"LocationType\",StringType(),True),\n",
    "      StructField(\"Lat\",DoubleType(),True),\n",
    "      StructField(\"Long\",DoubleType(),True),\n",
    "      StructField(\"Xaxis\",IntegerType(),True),\n",
    "      StructField(\"Yaxis\",DoubleType(),True),\n",
    "      StructField(\"Zaxis\",DoubleType(),True),\n",
    "      StructField(\"WorldRegion\",StringType(),True),\n",
    "      StructField(\"Country\",StringType(),True),\n",
    "      StructField(\"LocationText\",StringType(),True),\n",
    "      StructField(\"Location\",StringType(),True),\n",
    "      StructField(\"Decommisioned\",BooleanType(),True),\n",
    "      StructField(\"TaxReturnsFiled\",StringType(),True),\n",
    "      StructField(\"EstimatedPopulation\",IntegerType(),True),\n",
    "      StructField(\"TotalWages\",IntegerType(),True),\n",
    "      StructField(\"Notes\",StringType(),True)\n",
    "  ])\n",
    "\n",
    "df_with_schema = spark.read.schema(schema).json(\"C:/Users/SGKsk/Downloads/zipcode.json\")\n",
    "df_with_schema.printSchema()\n",
    "df_with_schema.show(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop Spark session when done using SparkSQL\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
